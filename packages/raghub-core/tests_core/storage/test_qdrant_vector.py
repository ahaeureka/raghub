"""
QdrantVector å•å…ƒæµ‹è¯•

æµ‹è¯• QdrantVector çš„å„ç§åŠŸèƒ½ï¼Œä½¿ç”¨æœ¬åœ° Qdrant å®ä¾‹
"""

from __future__ import annotations

import asyncio
from pathlib import Path
from typing import List, Optional

import numpy as np
import pytest

try:
    import qdrant_client  # noqa: F401
    from langchain_qdrant import QdrantVectorStore  # noqa: F401

    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False

from raghub_core.embedding.base_embedding import BaseEmbedding
from raghub_core.schemas.document import Document


def create_test_qdrant_vector(embedder, persist_directory):
    """ä¸ºæµ‹è¯•åˆ›å»ºéå•ä¾‹çš„QdrantVectorå®ä¾‹"""
    from raghub_core.storage.qdrant_vector import QdrantVector
    from raghub_core.utils.class_meta import SingletonRegisterMeta

    # ä¸´æ—¶æ¸…é™¤å•ä¾‹ç¼“å­˜ä¸­è¯¥ç±»çš„å®ä¾‹ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
    if QdrantVector in SingletonRegisterMeta._instances:
        del SingletonRegisterMeta._instances[QdrantVector]

    # åˆ›å»ºæ–°å®ä¾‹
    instance = QdrantVector(embedder=embedder, persist_directory=persist_directory)

    # å†æ¬¡æ¸…é™¤ç¼“å­˜ï¼Œç¡®ä¿ä¸‹æ¬¡æµ‹è¯•è·å¾—æ–°å®ä¾‹
    if QdrantVector in SingletonRegisterMeta._instances:
        del SingletonRegisterMeta._instances[QdrantVector]

    return instance


class MockEmbedding(BaseEmbedding):
    """ç”¨äºæµ‹è¯•çš„ç®€å•embeddingå®ç°"""

    name = "mock_embedding"

    def __init__(self, embedding_dim: int = 384):
        super().__init__()
        self.n_dim = embedding_dim
        # ä¸ºä¸€è‡´æ€§é¢„è®¾ä¸€äº›å›ºå®šçš„embeddings
        self._fixed_embeddings = {
            "test document 1": np.random.RandomState(42).randn(embedding_dim).astype(np.float32),
            "test document 2": np.random.RandomState(43).randn(embedding_dim).astype(np.float32),
            "programming tutorial": np.random.RandomState(44).randn(embedding_dim).astype(np.float32),
            "machine learning": np.random.RandomState(45).randn(embedding_dim).astype(np.float32),
            "python guide": np.random.RandomState(46).randn(embedding_dim).astype(np.float32),
        }

    @property
    def embedding_dim(self):
        return self.n_dim

    def encode(self, texts: List[str], instruction: Optional[str] = None) -> np.ndarray:
        """è¿”å›å›ºå®šçš„embeddingsä»¥ä¿è¯æµ‹è¯•ä¸€è‡´æ€§"""
        embeddings = []
        for text in texts:
            if text in self._fixed_embeddings:
                embeddings.append(self._fixed_embeddings[text])
            else:
                # ä¸ºæ–°æ–‡æœ¬ç”Ÿæˆä¸€è‡´çš„embedding
                hash_seed = hash(text) % (2**31)
                embeddings.append(np.random.RandomState(hash_seed).randn(self.embedding_dim).astype(np.float32))
        return np.array(embeddings)

    def encode_query(self, query: str, instruction: Optional[str] = None) -> np.ndarray:
        """è¿”å›æŸ¥è¯¢çš„embedding"""
        return self.encode([query])[0]

    async def aencode(self, texts: List[str], instruction: Optional[str] = None) -> np.ndarray:
        """å¼‚æ­¥ç‰ˆæœ¬çš„encode"""
        return self.encode(texts, instruction)

    async def aencode_query(self, query: List[str], instruction: Optional[str] = None) -> np.ndarray:
        """å¼‚æ­¥ç‰ˆæœ¬çš„encode_query"""
        if isinstance(query, list):
            return self.encode(query, instruction)
        else:
            return self.encode([query], instruction)[0]


@pytest.mark.skipif(not QDRANT_AVAILABLE, reason="qdrant-client or langchain-qdrant not installed")
class TestQdrantVector:
    """QdrantVector æµ‹è¯•ç±»"""

    @pytest.fixture
    def mock_embedder(self):
        """åˆ›å»ºmock embedderå®ä¾‹"""
        return MockEmbedding(embedding_dim=384)

    @pytest.fixture
    async def qdrant_vector(self, mock_embedder, tmp_path, request):
        """åˆ›å»ºQdrantVectorå®ä¾‹ï¼Œä¸ºæ¯ä¸ªæµ‹è¯•æ–¹æ³•åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„å®ä¾‹"""
        import time
        import uuid

        from raghub_core.storage.qdrant_vector import QdrantVector
        from raghub_core.utils.class_meta import SingletonRegisterMeta

        # æ¸…ç†å•ä¾‹ç¼“å­˜ï¼Œç¡®ä¿è·å¾—å…¨æ–°å®ä¾‹
        if QdrantVector in SingletonRegisterMeta._instances:
            del SingletonRegisterMeta._instances[QdrantVector]

        # ä¸ºæ¯ä¸ªæµ‹è¯•åˆ›å»ºå”¯ä¸€çš„ç›®å½•åï¼ŒåŒ…å«æµ‹è¯•åå’Œæ—¶é—´æˆ³
        test_name = request.node.name.replace("[", "_").replace("]", "_")
        unique_id = str(uuid.uuid4())[:8]
        timestamp = str(int(time.time() * 1000))
        test_dir = tmp_path / f"qdrant_{test_name}_{unique_id}_{timestamp}"

        vector_store = QdrantVector(embedder=mock_embedder, persist_directory=test_dir)
        await vector_store.init()

        yield vector_store

        # æµ‹è¯•åæ¸…ç†ï¼šå†æ¬¡æ¸…ç†å•ä¾‹ç¼“å­˜ï¼Œç¡®ä¿ä¸‹ä¸ªæµ‹è¯•è·å¾—æ–°å®ä¾‹
        try:
            if QdrantVector in SingletonRegisterMeta._instances:
                del SingletonRegisterMeta._instances[QdrantVector]
        except Exception:
            # å¿½ç•¥æ¸…ç†é”™è¯¯
            pass

    @pytest.fixture
    def sample_documents(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„æ–‡æ¡£"""
        return [
            Document(
                content="test document 1",
                metadata={"category": "programming", "priority": 5, "tags": ["python", "tutorial"]},
                uid="11111111-1111-1111-1111-111111111111",
                summary="A programming tutorial",
            ),
            Document(
                content="test document 2",
                metadata={"category": "machine-learning", "priority": 3, "tags": ["ai", "ml"]},
                uid="22222222-2222-2222-2222-222222222222",
                summary="An ML guide",
            ),
            Document(
                content="programming tutorial",
                metadata={"category": "programming", "priority": 4, "tags": ["coding", "beginner"]},
                uid="33333333-3333-3333-3333-333333333333",
                summary="Basic programming concepts",
            ),
        ]

    @pytest.mark.asyncio
    async def test_initialization(self, mock_embedder, tmp_path):
        """æµ‹è¯•QdrantVectoråˆå§‹åŒ–"""
        import time
        import uuid

        from raghub_core.storage.qdrant_vector import QdrantVector
        from raghub_core.utils.class_meta import SingletonRegisterMeta

        # æ¸…ç†å•ä¾‹ç¼“å­˜
        if QdrantVector in SingletonRegisterMeta._instances:
            del SingletonRegisterMeta._instances[QdrantVector]

        # ä¸ºåˆå§‹åŒ–æµ‹è¯•åˆ›å»ºå”¯ä¸€çš„ç›®å½•å
        unique_id = str(uuid.uuid4())[:8]
        timestamp = str(int(time.time() * 1000))
        test_dir = tmp_path / f"test_init_{unique_id}_{timestamp}"
        vector_store = QdrantVector(embedder=mock_embedder, persist_directory=test_dir)

        assert vector_store._embedder == mock_embedder
        assert vector_store._persist_directory == test_dir
        assert vector_store._client is None  # Lazy loading
        assert len(vector_store._vector_stores) == 0

        # æµ‹è¯•åæ¸…ç†å•ä¾‹ç¼“å­˜
        if QdrantVector in SingletonRegisterMeta._instances:
            del SingletonRegisterMeta._instances[QdrantVector]

    @pytest.mark.asyncio
    async def test_client_lazy_loading(self, qdrant_vector):
        """æµ‹è¯•å®¢æˆ·ç«¯æ‡’åŠ è½½"""
        # ç¬¬ä¸€æ¬¡è®¿é—®æ—¶åˆ›å»ºå®¢æˆ·ç«¯
        client1 = qdrant_vector.client
        assert client1 is not None

        # ç¬¬äºŒæ¬¡è®¿é—®åº”è¯¥è¿”å›åŒä¸€ä¸ªå®¢æˆ·ç«¯
        client2 = qdrant_vector.client
        assert client1 is client2

    @pytest.mark.asyncio
    async def test_create_index(self, qdrant_vector):
        """æµ‹è¯•åˆ›å»ºç´¢å¼•"""
        index_name = "test_index"

        # åˆ›å»ºç´¢å¼•
        vector_store = qdrant_vector.create_index(index_name)
        assert vector_store is not None
        assert index_name in qdrant_vector._vector_stores

        # å†æ¬¡åˆ›å»ºç›¸åŒç´¢å¼•åº”è¯¥è¿”å›ç¼“å­˜çš„å®ä¾‹
        vector_store2 = qdrant_vector.create_index(index_name)
        assert vector_store is vector_store2

    @pytest.mark.asyncio
    async def test_add_documents(self, qdrant_vector, sample_documents):
        """æµ‹è¯•æ·»åŠ æ–‡æ¡£"""
        index_name = "test_add_docs"

        # æ·»åŠ æ–‡æ¡£
        added_docs = await qdrant_vector.add_documents(index_name, sample_documents)

        assert len(added_docs) == len(sample_documents)

        # æ£€æŸ¥å†…å®¹æ˜¯å¦æ­£ç¡®ï¼ˆä¸ä¾èµ–UIDé¡ºåºï¼Œå› ä¸ºLangChainå¯èƒ½é‡æ–°ç”ŸæˆIDï¼‰
        added_contents = {doc.content for doc in added_docs}
        expected_contents = {doc.content for doc in sample_documents}
        assert added_contents == expected_contents

        # æ£€æŸ¥æ¯ä¸ªæ–‡æ¡£éƒ½æœ‰valid ID
        for doc in added_docs:
            assert doc.uid is not None
            assert doc.content is not None
            assert doc.metadata is not None

    @pytest.mark.asyncio
    async def test_get_document_by_id(self, qdrant_vector, sample_documents):
        """æµ‹è¯•é€šè¿‡IDè·å–æ–‡æ¡£"""
        index_name = "test_get_doc"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # é€šè¿‡IDè·å–æ–‡æ¡£
        doc = await qdrant_vector.get(index_name, "11111111-1111-1111-1111-111111111111")
        assert doc.uid == "11111111-1111-1111-1111-111111111111"
        assert doc.content == "test document 1"
        assert doc.metadata["category"] == "programming"

    @pytest.mark.asyncio
    async def test_get_documents_by_ids(self, qdrant_vector, sample_documents):
        """æµ‹è¯•é€šè¿‡IDåˆ—è¡¨è·å–æ–‡æ¡£"""
        index_name = "test_get_docs"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # é€šè¿‡IDåˆ—è¡¨è·å–æ–‡æ¡£
        docs = await qdrant_vector.get_by_ids(
            index_name, ["11111111-1111-1111-1111-111111111111", "33333333-3333-3333-3333-333333333333"]
        )
        assert len(docs) == 2

        doc_ids = [doc.uid for doc in docs]
        assert "11111111-1111-1111-1111-111111111111" in doc_ids
        assert "33333333-3333-3333-3333-333333333333" in doc_ids

    @pytest.mark.asyncio
    async def test_get_by_ids_empty_list(self, qdrant_vector):
        """æµ‹è¯•ç©ºIDåˆ—è¡¨"""
        index_name = "test_empty_ids"
        docs = await qdrant_vector.get_by_ids(index_name, [])
        assert docs == []

    @pytest.mark.asyncio
    async def test_get_nonexistent_document(self, qdrant_vector, sample_documents):
        """æµ‹è¯•è·å–ä¸å­˜åœ¨çš„æ–‡æ¡£"""
        index_name = "test_nonexistent"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # å°è¯•è·å–ä¸å­˜åœ¨çš„æ–‡æ¡£
        with pytest.raises(ValueError, match="Document with ID nonexistent not found"):
            await qdrant_vector.get(index_name, "nonexistent")

    @pytest.mark.asyncio
    async def test_delete_documents(self, qdrant_vector, sample_documents):
        """æµ‹è¯•åˆ é™¤æ–‡æ¡£"""
        index_name = "test_delete"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # åˆ é™¤éƒ¨åˆ†æ–‡æ¡£
        success = await qdrant_vector.delete(
            index_name, ["11111111-1111-1111-1111-111111111111", "22222222-2222-2222-2222-222222222222"]
        )
        assert success is True

        # éªŒè¯æ–‡æ¡£å·²è¢«åˆ é™¤
        with pytest.raises(ValueError):
            await qdrant_vector.get(index_name, "11111111-1111-1111-1111-111111111111")

        # éªŒè¯æœªåˆ é™¤çš„æ–‡æ¡£ä»ç„¶å­˜åœ¨
        doc3 = await qdrant_vector.get(index_name, "33333333-3333-3333-3333-333333333333")
        assert doc3.uid == "33333333-3333-3333-3333-333333333333"

    @pytest.mark.asyncio
    async def test_delete_empty_list(self, qdrant_vector):
        """æµ‹è¯•åˆ é™¤ç©ºIDåˆ—è¡¨"""
        index_name = "test_delete_empty"
        success = await qdrant_vector.delete(index_name, [])
        assert success is False

    @pytest.mark.asyncio
    async def test_similarity_search_by_vector(self, qdrant_vector, sample_documents):
        """æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦æœç´¢"""
        index_name = "test_similarity_vector"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # åˆ›å»ºæŸ¥è¯¢å‘é‡
        query_embedding = qdrant_vector._embedder.encode_query("programming tutorial")

        # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
        results = await qdrant_vector.similarity_search_by_vector(index_name, query_embedding.tolist(), k=2)

        assert len(results) <= 2
        for doc, score in results:
            assert isinstance(doc, Document)
            assert isinstance(score, (int, float))
            assert 0 <= score <= 1

    @pytest.mark.asyncio
    async def test_similarity_search_with_query(self, qdrant_vector, sample_documents):
        """æµ‹è¯•æŸ¥è¯¢å­—ç¬¦ä¸²ç›¸ä¼¼åº¦æœç´¢"""
        index_name = "test_similarity_query"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
        results = await qdrant_vector.asimilar_search_with_scores(index_name, "programming tutorial", k=2)

        assert len(results) <= 2
        for doc, score in results:
            assert isinstance(doc, Document)
            assert isinstance(score, (int, float))

    @pytest.mark.asyncio
    async def test_metadata_condition_format_detection(self, qdrant_vector):
        """æµ‹è¯•å…ƒæ•°æ®æ¡ä»¶æ ¼å¼æ£€æµ‹"""
        # MetadataConditionæ ¼å¼
        metadata_condition = {
            "logical_operator": "and",
            "conditions": [{"name": ["category"], "comparison_operator": "is", "value": "programming"}],
        }
        assert qdrant_vector._is_metadata_condition_format(metadata_condition) is True

        # ç®€å•æ ¼å¼
        simple_filter = {"category": "programming", "priority": 5}
        assert qdrant_vector._is_metadata_condition_format(simple_filter) is False

        # ç©ºæ¡ä»¶
        empty_condition = {"logical_operator": "and", "conditions": []}
        assert qdrant_vector._is_metadata_condition_format(empty_condition) is False

    @pytest.mark.asyncio
    async def test_select_on_metadata_simple_format(self, qdrant_vector, sample_documents):
        """æµ‹è¯•ç®€å•æ ¼å¼çš„å…ƒæ•°æ®é€‰æ‹©"""
        index_name = "test_metadata_simple"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # ä½¿ç”¨ç®€å•æ ¼å¼è¿‡æ»¤
        docs = await qdrant_vector.select_on_metadata(index_name, {"category": "programming"})

        assert len(docs) >= 1
        for doc in docs:
            assert doc.metadata["category"] == "programming"

    @pytest.mark.asyncio
    async def test_select_on_metadata_condition_format(self, qdrant_vector, sample_documents):
        """æµ‹è¯•MetadataConditionæ ¼å¼çš„å…ƒæ•°æ®é€‰æ‹©"""
        index_name = "test_metadata_condition"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # ä½¿ç”¨MetadataConditionæ ¼å¼è¿‡æ»¤
        metadata_condition = {
            "logical_operator": "and",
            "conditions": [{"name": ["category"], "comparison_operator": "is", "value": "programming"}],
        }
        docs = await qdrant_vector.select_on_metadata(index_name, metadata_condition)

        assert len(docs) >= 1
        for doc in docs:
            assert doc.metadata["category"] == "programming"

    @pytest.mark.asyncio
    async def test_select_on_metadata_list_values(self, qdrant_vector, sample_documents):
        """æµ‹è¯•åŒ…å«åˆ—è¡¨å€¼çš„å…ƒæ•°æ®é€‰æ‹©"""
        index_name = "test_metadata_list"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # ä½¿ç”¨åˆ—è¡¨å€¼è¿‡æ»¤ï¼ˆORæ¡ä»¶ï¼‰
        docs = await qdrant_vector.select_on_metadata(index_name, {"category": ["programming", "machine-learning"]})

        assert len(docs) >= 2
        categories = [doc.metadata["category"] for doc in docs]
        assert "programming" in categories or "machine-learning" in categories

    @pytest.mark.asyncio
    async def test_select_on_metadata_empty_filter(self, qdrant_vector, sample_documents):
        """æµ‹è¯•ç©ºè¿‡æ»¤æ¡ä»¶"""
        index_name = "test_metadata_empty"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # ç©ºè¿‡æ»¤æ¡ä»¶åº”è¯¥è¿”å›ç©ºåˆ—è¡¨
        docs = await qdrant_vector.select_on_metadata(index_name, {})
        assert docs == []

    @pytest.mark.asyncio
    async def test_similarity_search_with_filter(self, qdrant_vector, sample_documents):
        """æµ‹è¯•å¸¦è¿‡æ»¤å™¨çš„ç›¸ä¼¼åº¦æœç´¢"""
        index_name = "test_similarity_filter"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, sample_documents)

        # æ‰§è¡Œå¸¦è¿‡æ»¤å™¨çš„ç›¸ä¼¼åº¦æœç´¢
        results = await qdrant_vector.asimilar_search_with_scores(
            index_name, "tutorial", k=5, filter={"category": "programming"}
        )

        # éªŒè¯æ‰€æœ‰ç»“æœéƒ½ç¬¦åˆè¿‡æ»¤æ¡ä»¶
        for doc, score in results:
            assert doc.metadata["category"] == "programming"

    @pytest.mark.asyncio
    async def test_get_vector_store(self, qdrant_vector):
        """æµ‹è¯•è·å–vector store"""
        index_name = "test_get_vector_store"

        vector_store = qdrant_vector.get_vector_store(index_name)
        assert vector_store is not None
        assert index_name in qdrant_vector._vector_stores

    @pytest.mark.asyncio
    async def test_persist_directory_property(self, qdrant_vector):
        """æµ‹è¯•persist_directoryå±æ€§"""
        # æ£€æŸ¥persist_directoryå±æ€§æ˜¯å¦æ­£ç¡®è®¾ç½®
        assert qdrant_vector.persist_directory is not None
        assert isinstance(qdrant_vector.persist_directory, Path)

    @pytest.mark.asyncio
    async def test_build_docs_helper(self, qdrant_vector):
        """æµ‹è¯•_build_docsè¾…åŠ©æ–¹æ³•"""
        from langchain_core.documents import Document as LangchainDocument

        langchain_docs = [
            LangchainDocument(
                page_content="test content", metadata={"category": "test", "summary": "test summary"}, id="test_id"
            )
        ]

        docs = qdrant_vector._build_docs(langchain_docs)

        assert len(docs) == 1
        doc = docs[0]
        assert doc.content == "test content"
        assert doc.metadata["category"] == "test"
        assert doc.uid == "test_id"
        assert doc.summary == "test summary"

    @pytest.mark.asyncio
    async def test_error_handling_invalid_index(self, qdrant_vector):
        """æµ‹è¯•æ— æ•ˆç´¢å¼•çš„é”™è¯¯å¤„ç†"""
        # è¿™é‡Œæˆ‘ä»¬æµ‹è¯•ä¸€äº›å¯èƒ½çš„é”™è¯¯æƒ…å†µ
        # æ³¨æ„ï¼šç”±äºä½¿ç”¨æœ¬åœ°Qdrantï¼ŒæŸäº›é”™è¯¯å¯èƒ½ä¸ä¼šå‘ç”Ÿ

        # æµ‹è¯•è·å–ä¸å­˜åœ¨çš„æ–‡æ¡£
        with pytest.raises(ValueError):
            await qdrant_vector.get("nonexistent_index", "nonexistent_doc")

    @pytest.mark.asyncio
    async def test_concurrent_operations(self, qdrant_vector, sample_documents):
        """æµ‹è¯•å¹¶å‘æ“ä½œ"""
        index_name = "test_concurrent"

        # å¹¶å‘æ·»åŠ æ–‡æ¡£
        tasks = []
        for i in range(3):
            doc_batch = [
                Document(
                    content=f"concurrent document {i}-{j}",
                    metadata={"batch": i, "seq": j},
                    uid=f"{i:08d}-{j:04d}-{j:04d}-{j:04d}-{i:012d}",  # ç”Ÿæˆ UUID æ ¼å¼çš„ ID
                    summary=f"Summary {i}-{j}",
                )
                for j in range(2)
            ]
            tasks.append(qdrant_vector.add_documents(f"{index_name}_{i}", doc_batch))

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks)

        # éªŒè¯ç»“æœ
        for i, result in enumerate(results):
            assert len(result) == 2
            for doc in result:
                assert doc.metadata["batch"] == i


@pytest.mark.skipif(not QDRANT_AVAILABLE, reason="qdrant-client or langchain-qdrant not installed")
class TestQdrantVectorEdgeCases:
    """QdrantVectorè¾¹ç•Œæƒ…å†µæµ‹è¯•"""

    @pytest.fixture
    def mock_embedder(self):
        """åˆ›å»ºmock embedderå®ä¾‹"""
        return MockEmbedding(embedding_dim=384)

    @pytest.fixture
    async def qdrant_vector(self, mock_embedder, tmp_path, request):
        """åˆ›å»ºQdrantVectorå®ä¾‹ï¼Œä¸ºæ¯ä¸ªæµ‹è¯•æ–¹æ³•åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„å®ä¾‹"""
        import time
        import uuid

        from raghub_core.storage.qdrant_vector import QdrantVector

        # ä¸ºè¾¹ç•Œæƒ…å†µæµ‹è¯•åˆ›å»ºå”¯ä¸€çš„ç›®å½•åï¼ŒåŒ…å«æµ‹è¯•åå’Œæ—¶é—´æˆ³
        test_name = request.node.name.replace("[", "_").replace("]", "_")
        unique_id = str(uuid.uuid4())[:8]
        timestamp = str(int(time.time() * 1000))
        test_dir = tmp_path / f"qdrant_edge_{test_name}_{unique_id}_{timestamp}"

        vector_store = QdrantVector(embedder=mock_embedder, persist_directory=test_dir)
        await vector_store.init()

        yield vector_store

        # æ˜¾å¼æ¸…ç†
        try:
            # å…³é—­æ‰€æœ‰å¯èƒ½çš„è¿æ¥
            if hasattr(vector_store, "_vector_stores"):
                for store in vector_store._vector_stores.values():
                    if hasattr(store, "client") and hasattr(store.client, "_client"):
                        client = store.client._client
                        if hasattr(client, "_flock_file") and client._flock_file:
                            client._flock_file.close()
                        if hasattr(client, "close"):
                            client.close()
        except Exception:
            # å¿½ç•¥æ¸…ç†é”™è¯¯
            pass

    @pytest.mark.asyncio
    async def test_empty_document_list(self, qdrant_vector):
        """æµ‹è¯•æ·»åŠ ç©ºæ–‡æ¡£åˆ—è¡¨"""
        index_name = "test_empty_docs"
        result = await qdrant_vector.add_documents(index_name, [])
        assert result == []

    @pytest.mark.asyncio
    async def test_document_with_none_metadata(self, qdrant_vector):
        """æµ‹è¯•åŒ…å«Noneå…ƒæ•°æ®çš„æ–‡æ¡£"""
        index_name = "test_none_metadata"
        doc = Document(content="test content", metadata=None, uid="test_none", summary="test summary")

        result = await qdrant_vector.add_documents(index_name, [doc])
        assert len(result) == 1
        assert result[0].metadata is not None  # åº”è¯¥è¢«è½¬æ¢ä¸ºç©ºå­—å…¸

    @pytest.mark.asyncio
    async def test_special_characters_in_content(self, qdrant_vector):
        """æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡æ¡£å†…å®¹"""
        index_name = "test_special_chars"
        doc = Document(
            content="æµ‹è¯•ä¸­æ–‡ï¼Œemoji ğŸ˜€ï¼Œç‰¹æ®Šç¬¦å· @#$%^&*()",
            metadata={"type": "special"},
            uid="special_doc",
            summary="ç‰¹æ®Šå­—ç¬¦æµ‹è¯•",
        )

        result = await qdrant_vector.add_documents(index_name, [doc])
        assert len(result) == 1

        retrieved_doc = await qdrant_vector.get(index_name, "special_doc")
        assert retrieved_doc.content == doc.content

    @pytest.mark.asyncio
    async def test_very_long_document(self, qdrant_vector):
        """æµ‹è¯•éå¸¸é•¿çš„æ–‡æ¡£"""
        index_name = "test_long_doc"
        long_content = "Long document content. " * 1000  # çº¦23KBçš„å†…å®¹

        doc = Document(content=long_content, metadata={"type": "long"}, uid="long_doc", summary="Very long document")

        result = await qdrant_vector.add_documents(index_name, [doc])
        assert len(result) == 1

        retrieved_doc = await qdrant_vector.get(index_name, "long_doc")
        assert len(retrieved_doc.content) == len(long_content)


@pytest.mark.skipif(not QDRANT_AVAILABLE, reason="qdrant-client or langchain-qdrant not installed")
class TestQdrantVectorSnowflakeID:
    """QdrantVectoré›ªèŠ±IDè½¬æ¢æµ‹è¯•"""

    @pytest.fixture
    def mock_embedder(self):
        """åˆ›å»ºmock embedderå®ä¾‹"""
        return MockEmbedding(embedding_dim=384)

    @pytest.fixture
    async def qdrant_vector(self, mock_embedder, tmp_path, request):
        """åˆ›å»ºQdrantVectorå®ä¾‹ï¼Œä¸ºæ¯ä¸ªæµ‹è¯•æ–¹æ³•åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„å®ä¾‹"""
        import time
        import uuid

        from raghub_core.storage.qdrant_vector import QdrantVector
        from raghub_core.utils.class_meta import SingletonRegisterMeta

        # æ¸…ç†å•ä¾‹ç¼“å­˜ï¼Œç¡®ä¿è·å¾—å…¨æ–°å®ä¾‹
        if QdrantVector in SingletonRegisterMeta._instances:
            del SingletonRegisterMeta._instances[QdrantVector]

        # ä¸ºæ¯ä¸ªæµ‹è¯•åˆ›å»ºå”¯ä¸€çš„ç›®å½•åï¼ŒåŒ…å«æµ‹è¯•åå’Œæ—¶é—´æˆ³
        test_name = request.node.name.replace("[", "_").replace("]", "_")
        unique_id = str(uuid.uuid4())[:8]
        timestamp = str(int(time.time() * 1000))
        test_dir = tmp_path / f"qdrant_snowflake_{test_name}_{unique_id}_{timestamp}"

        vector_store = QdrantVector(embedder=mock_embedder, persist_directory=test_dir)
        await vector_store.init()

        yield vector_store

        # æµ‹è¯•åæ¸…ç†ï¼šå†æ¬¡æ¸…ç†å•ä¾‹ç¼“å­˜ï¼Œç¡®ä¿ä¸‹ä¸ªæµ‹è¯•è·å¾—æ–°å®ä¾‹
        try:
            if QdrantVector in SingletonRegisterMeta._instances:
                del SingletonRegisterMeta._instances[QdrantVector]
        except Exception:
            # å¿½ç•¥æ¸…ç†é”™è¯¯
            pass

    @pytest.fixture
    def snowflake_documents(self):
        """åˆ›å»ºä½¿ç”¨é›ªèŠ±IDçš„æµ‹è¯•æ–‡æ¡£"""
        return [
            Document(
                content="Test document with snowflake ID 1",
                metadata={"category": "test", "type": "snowflake", "priority": 1},
                uid="1234567890123456789",  # å…¸å‹19ä½é›ªèŠ±ID
                summary="First snowflake document",
            ),
            Document(
                content="Test document with snowflake ID 2",
                metadata={"category": "test", "type": "snowflake", "priority": 2},
                uid="987654321098765432",  # å¦ä¸€ä¸ª18ä½é›ªèŠ±ID
                summary="Second snowflake document",
            ),
            Document(
                content="Test document with shorter ID",
                metadata={"category": "test", "type": "snowflake", "priority": 3},
                uid="123456789",  # è¾ƒçŸ­çš„9ä½æ•°å­—ID
                summary="Shorter ID document",
            ),
        ]

    @pytest.mark.asyncio
    async def test_is_snowflake_id(self, qdrant_vector):
        """æµ‹è¯•é›ªèŠ±IDæ£€æµ‹å‡½æ•°"""
        # æµ‹è¯•å…¸å‹é›ªèŠ±ID
        assert qdrant_vector._is_snowflake_id("1234567890123456789") is True
        assert qdrant_vector._is_snowflake_id("987654321098765432") is True
        assert qdrant_vector._is_snowflake_id("123456789012") is True  # 12ä½æ•°å­—

        # æµ‹è¯•è¾¹ç•Œæƒ…å†µ
        assert qdrant_vector._is_snowflake_id("1234567890") is True  # åˆšå¥½10ä½
        assert qdrant_vector._is_snowflake_id("123456789") is True  # 9ä½ï¼Œä»ç„¶æ˜¯æœ‰æ•ˆçš„é›ªèŠ±ID
        assert qdrant_vector._is_snowflake_id("123") is True  # 3ä½ï¼Œæœ€å°é•¿åº¦

        # æµ‹è¯•å¤ªçŸ­çš„æ•°å­—
        assert qdrant_vector._is_snowflake_id("12") is False  # 2ä½ï¼Œå°äºæœ€å°é˜ˆå€¼

        # æµ‹è¯•éæ•°å­—å­—ç¬¦ä¸²
        assert qdrant_vector._is_snowflake_id("abc123") is False
        assert qdrant_vector._is_snowflake_id("123abc456") is False
        assert qdrant_vector._is_snowflake_id("") is False

        # æµ‹è¯•UUIDæ ¼å¼
        assert qdrant_vector._is_snowflake_id("550e8400-e29b-41d4-a716-446655440000") is False

    @pytest.mark.asyncio
    async def test_is_uuid_format(self, qdrant_vector):
        """æµ‹è¯•UUIDæ ¼å¼æ£€æµ‹å‡½æ•°"""
        import uuid

        # æµ‹è¯•æ ‡å‡†UUID
        test_uuid = str(uuid.uuid4())
        assert qdrant_vector._is_uuid_format(test_uuid) is True
        assert qdrant_vector._is_uuid_format("550e8400-e29b-41d4-a716-446655440000") is True

        # æµ‹è¯•éUUIDæ ¼å¼
        assert qdrant_vector._is_uuid_format("1234567890123456789") is False
        assert qdrant_vector._is_uuid_format("not-a-uuid") is False
        assert qdrant_vector._is_uuid_format("") is False

    @pytest.mark.asyncio
    async def test_snowflake_to_uuid_conversion(self, qdrant_vector):
        """æµ‹è¯•é›ªèŠ±IDåˆ°UUIDçš„è½¬æ¢"""
        test_cases = [
            "1234567890123456789",  # å…¸å‹19ä½é›ªèŠ±ID
            "987654321098765432",  # å¦ä¸€ä¸ª18ä½é›ªèŠ±ID
            "123456789012345",  # 15ä½é›ªèŠ±ID
        ]

        for snowflake_id in test_cases:
            uuid_id = qdrant_vector._snowflake_to_uuid(snowflake_id)

            # éªŒè¯ç»“æœæ˜¯æœ‰æ•ˆçš„UUID
            assert qdrant_vector._is_uuid_format(uuid_id) is True

            # éªŒè¯è½¬æ¢çš„ä¸€è‡´æ€§ï¼ˆåŒæ ·çš„è¾“å…¥äº§ç”ŸåŒæ ·çš„è¾“å‡ºï¼‰
            uuid_id2 = qdrant_vector._snowflake_to_uuid(snowflake_id)
            assert uuid_id == uuid_id2

    @pytest.mark.asyncio
    async def test_uuid_to_snowflake_conversion(self, qdrant_vector):
        """æµ‹è¯•UUIDåˆ°é›ªèŠ±IDçš„è½¬æ¢"""
        test_snowflake_ids = [
            "1234567890123456789",
            "987654321098765432",
            "123456789012345",
        ]

        for original_snowflake_id in test_snowflake_ids:
            # è½¬æ¢ä¸ºUUIDå†è½¬æ¢å›æ¥
            uuid_id = qdrant_vector._snowflake_to_uuid(original_snowflake_id)
            recovered_snowflake_id = qdrant_vector._uuid_to_snowflake(uuid_id)

            # éªŒè¯èƒ½å¤Ÿæ­£ç¡®æ¢å¤
            assert recovered_snowflake_id == original_snowflake_id

    @pytest.mark.asyncio
    async def test_uuid_passthrough(self, qdrant_vector):
        """æµ‹è¯•UUIDåº”è¯¥ç›´æ¥é€šè¿‡è½¬æ¢å‡½æ•°"""
        import uuid

        test_uuid = str(uuid.uuid4())

        # UUIDåº”è¯¥ç›´æ¥é€šè¿‡snowflake_to_uuid
        result_uuid = qdrant_vector._snowflake_to_uuid(test_uuid)
        assert result_uuid == test_uuid

        # UUIDåº”è¯¥ç›´æ¥é€šè¿‡uuid_to_snowflake
        result_uuid2 = qdrant_vector._uuid_to_snowflake(test_uuid)
        assert result_uuid2 == test_uuid

    @pytest.mark.asyncio
    async def test_add_documents_with_snowflake_ids(self, qdrant_vector, snowflake_documents):
        """æµ‹è¯•ä½¿ç”¨é›ªèŠ±IDæ·»åŠ æ–‡æ¡£"""
        index_name = "test_snowflake_add"

        # æ·»åŠ æ–‡æ¡£
        added_docs = await qdrant_vector.add_documents(index_name, snowflake_documents)

        # éªŒè¯è¿”å›çš„æ–‡æ¡£æ•°é‡
        assert len(added_docs) == len(snowflake_documents)

        # éªŒè¯è¿”å›çš„æ–‡æ¡£IDä»ç„¶æ˜¯åŸå§‹çš„é›ªèŠ±IDæ ¼å¼
        for i, (original_doc, added_doc) in enumerate(zip(snowflake_documents, added_docs)):
            assert added_doc.uid == original_doc.uid, f"Document {i}: ID mismatch"
            assert added_doc.content == original_doc.content, f"Document {i}: Content mismatch"
            assert added_doc.metadata == original_doc.metadata, f"Document {i}: Metadata mismatch"

    @pytest.mark.asyncio
    async def test_get_document_by_snowflake_id(self, qdrant_vector, snowflake_documents):
        """æµ‹è¯•é€šè¿‡é›ªèŠ±IDè·å–æ–‡æ¡£"""
        index_name = "test_snowflake_get"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, snowflake_documents)

        # é€šè¿‡é›ªèŠ±IDè·å–æ–‡æ¡£
        for original_doc in snowflake_documents:
            retrieved_doc = await qdrant_vector.get(index_name, original_doc.uid)

            assert retrieved_doc.uid == original_doc.uid
            assert retrieved_doc.content == original_doc.content
            assert retrieved_doc.metadata["category"] == original_doc.metadata["category"]

    @pytest.mark.asyncio
    async def test_get_documents_by_snowflake_ids(self, qdrant_vector, snowflake_documents):
        """æµ‹è¯•é€šè¿‡é›ªèŠ±IDåˆ—è¡¨æ‰¹é‡è·å–æ–‡æ¡£"""
        index_name = "test_snowflake_get_batch"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, snowflake_documents)

        # æ‰¹é‡è·å–æ–‡æ¡£
        snowflake_ids = [doc.uid for doc in snowflake_documents]
        retrieved_docs = await qdrant_vector.get_by_ids(index_name, snowflake_ids)

        # éªŒè¯è¿”å›çš„æ–‡æ¡£æ•°é‡å’Œé¡ºåº
        assert len(retrieved_docs) == len(snowflake_documents)

        # éªŒè¯è¿”å›çš„æ–‡æ¡£é¡ºåºä¸è¯·æ±‚çš„IDé¡ºåºä¸€è‡´
        for i, (requested_id, retrieved_doc) in enumerate(zip(snowflake_ids, retrieved_docs)):
            assert retrieved_doc.uid == requested_id, f"Document {i}: ID order mismatch"

    @pytest.mark.asyncio
    async def test_delete_documents_by_snowflake_ids(self, qdrant_vector, snowflake_documents):
        """æµ‹è¯•é€šè¿‡é›ªèŠ±IDåˆ é™¤æ–‡æ¡£"""
        index_name = "test_snowflake_delete"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, snowflake_documents)

        # åˆ é™¤éƒ¨åˆ†æ–‡æ¡£
        ids_to_delete = [snowflake_documents[0].uid, snowflake_documents[1].uid]
        success = await qdrant_vector.delete(index_name, ids_to_delete)
        assert success is True

        # éªŒè¯åˆ é™¤çš„æ–‡æ¡£ä¸å†å­˜åœ¨
        for deleted_id in ids_to_delete:
            with pytest.raises(ValueError, match=f"Document with ID {deleted_id} not found"):
                await qdrant_vector.get(index_name, deleted_id)

        # éªŒè¯æœªåˆ é™¤çš„æ–‡æ¡£ä»ç„¶å­˜åœ¨
        remaining_doc = await qdrant_vector.get(index_name, snowflake_documents[2].uid)
        assert remaining_doc.uid == snowflake_documents[2].uid

    @pytest.mark.asyncio
    async def test_metadata_search_with_snowflake_ids(self, qdrant_vector, snowflake_documents):
        """æµ‹è¯•ä½¿ç”¨é›ªèŠ±IDçš„å…ƒæ•°æ®æœç´¢"""
        index_name = "test_snowflake_metadata"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, snowflake_documents)

        # é€šè¿‡å…ƒæ•°æ®æœç´¢
        results = await qdrant_vector.select_on_metadata(index_name, {"category": "test"})

        # éªŒè¯æœç´¢ç»“æœ
        assert len(results) == len(snowflake_documents)

        # éªŒè¯è¿”å›çš„æ–‡æ¡£ä»ç„¶ä½¿ç”¨é›ªèŠ±ID
        result_ids = [doc.uid for doc in results]
        expected_ids = [doc.uid for doc in snowflake_documents]

        for expected_id in expected_ids:
            assert expected_id in result_ids

    @pytest.mark.asyncio
    async def test_similarity_search_with_snowflake_ids(self, qdrant_vector, snowflake_documents):
        """æµ‹è¯•ä½¿ç”¨é›ªèŠ±IDçš„ç›¸ä¼¼åº¦æœç´¢"""
        index_name = "test_snowflake_similarity"

        # å…ˆæ·»åŠ æ–‡æ¡£
        await qdrant_vector.add_documents(index_name, snowflake_documents)

        # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
        results = await qdrant_vector.asimilar_search_with_scores(index_name, "test document", k=2)

        # éªŒè¯æœç´¢ç»“æœ
        assert len(results) <= 2

        for doc, score in results:
            # éªŒè¯è¿”å›çš„æ–‡æ¡£ä½¿ç”¨é›ªèŠ±ID
            assert qdrant_vector._is_snowflake_id(doc.uid) or qdrant_vector._is_uuid_format(doc.uid)
            assert isinstance(score, (int, float))

    @pytest.mark.asyncio
    async def test_mixed_id_formats(self, qdrant_vector):
        """æµ‹è¯•æ··åˆIDæ ¼å¼çš„å¤„ç†"""
        import uuid

        index_name = "test_mixed_ids"

        # åˆ›å»ºåŒ…å«ä¸åŒIDæ ¼å¼çš„æ–‡æ¡£
        mixed_docs = [
            Document(
                content="Document with snowflake ID",
                metadata={"type": "snowflake"},
                uid="1234567890123456789",  # é›ªèŠ±ID
                summary="Snowflake ID doc",
            ),
            Document(
                content="Document with UUID",
                metadata={"type": "uuid"},
                uid=str(uuid.uuid4()),  # UUID
                summary="UUID doc",
            ),
            Document(
                content="Document with string ID",
                metadata={"type": "string"},
                uid="custom_string_id_12345",  # è‡ªå®šä¹‰å­—ç¬¦ä¸²ID
                summary="String ID doc",
            ),
        ]

        # æ·»åŠ æ–‡æ¡£
        added_docs = await qdrant_vector.add_documents(index_name, mixed_docs)
        assert len(added_docs) == len(mixed_docs)

        # éªŒè¯æ¯ä¸ªæ–‡æ¡£éƒ½èƒ½æ­£ç¡®æ£€ç´¢
        for original_doc in mixed_docs:
            retrieved_doc = await qdrant_vector.get(index_name, original_doc.uid)
            assert retrieved_doc.uid == original_doc.uid
            assert retrieved_doc.content == original_doc.content

    @pytest.mark.asyncio
    async def test_conversion_consistency(self, qdrant_vector):
        """æµ‹è¯•è½¬æ¢ä¸€è‡´æ€§"""
        test_ids = [
            "1234567890123456789",
            "987654321098765432",
            "555444333222111000",
        ]

        for test_id in test_ids:
            # å¤šæ¬¡è½¬æ¢åº”è¯¥äº§ç”Ÿç›¸åŒç»“æœ
            uuid1 = qdrant_vector._snowflake_to_uuid(test_id)
            uuid2 = qdrant_vector._snowflake_to_uuid(test_id)
            assert uuid1 == uuid2

            # å¾€è¿”è½¬æ¢åº”è¯¥æ¢å¤åŸå§‹å€¼
            recovered = qdrant_vector._uuid_to_snowflake(uuid1)
            assert recovered == test_id

    @pytest.mark.asyncio
    async def test_edge_case_ids(self, qdrant_vector):
        """æµ‹è¯•è¾¹ç•Œæƒ…å†µçš„IDå¤„ç†"""
        # æµ‹è¯•æœ€å°çš„10ä½é›ªèŠ±ID
        min_snowflake = "1234567890"
        uuid_result = qdrant_vector._snowflake_to_uuid(min_snowflake)
        assert qdrant_vector._is_uuid_format(uuid_result)
        recovered = qdrant_vector._uuid_to_snowflake(uuid_result)
        assert recovered == min_snowflake

        # æµ‹è¯•ç©ºå­—ç¬¦ä¸²å’ŒNoneï¼ˆåº”è¯¥è¢«å®‰å…¨å¤„ç†ï¼‰
        empty_result = qdrant_vector._snowflake_to_uuid("")
        assert qdrant_vector._is_uuid_format(empty_result)

        # æµ‹è¯•éå¸¸é•¿çš„æ•°å­—å­—ç¬¦ä¸²
        very_long_id = "1" * 50  # 50ä½æ•°å­—
        long_uuid = qdrant_vector._snowflake_to_uuid(very_long_id)
        assert qdrant_vector._is_uuid_format(long_uuid)
        # éå¸¸é•¿çš„IDå¯èƒ½ä½¿ç”¨å“ˆå¸Œï¼Œæ‰€ä»¥ä¸ä¸€å®šèƒ½å®Œå…¨æ¢å¤
